{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85b415f9-41db-430d-a975-417b317ae086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>Suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>این اولین تجربه من برای خرید ایفون هست   امروز...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>خرید این محصول رو توصیه میکنم</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 ساله این گوشی رو دارم   هیچ نقطه ضعفی ازش ند...</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سلام خدمت دوستان این گوشی از همه نظر عالی  کیف...</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سلام دوستانی که نگران شکستن صفحه نمایش هستند ا...</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  Suggestion\n",
       "0  این اولین تجربه من برای خرید ایفون هست   امروز...    100           1\n",
       "1                     خرید این محصول رو توصیه میکنم      84           1\n",
       "2  1 ساله این گوشی رو دارم   هیچ نقطه ضعفی ازش ند...     60           1\n",
       "3  سلام خدمت دوستان این گوشی از همه نظر عالی  کیف...     96           1\n",
       "4  سلام دوستانی که نگران شکستن صفحه نمایش هستند ا...     92           1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07d20d-d95c-4019-b57b-0969f03af497",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e45c6fc7-10fa-4019-b613-aed2633d5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c831deb1-f799-4a3e-8793-9cc987079ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation += \"“”'s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802cf2e-e09d-4b40-a285-ff385902fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sents = [nltk.word_tokenize(i) for i in corpus]\n",
    "# tokenized_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f06b2dd1-b5c8-4279-86f3-611cfb98b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokenized_sentences, stop_words):\n",
    "    word_dict = set()\n",
    "    for  tokenized_sen in tokenized_sentences:\n",
    "        for word in tokenized_sen:\n",
    "            if word not in stop_words and word not in punctuation:\n",
    "                word_dict.add(word)\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45d3bcee-fdbe-4aef-b538-6932d57aad49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Andrés',\n",
       " 'Argentina',\n",
       " 'Argentine',\n",
       " 'Head',\n",
       " 'Here',\n",
       " 'Inter',\n",
       " 'League',\n",
       " 'Leo',\n",
       " 'Lionel',\n",
       " 'Major',\n",
       " 'Messi',\n",
       " 'Miami',\n",
       " 'Soccer',\n",
       " 'Store',\n",
       " 'Thank',\n",
       " 'The',\n",
       " 'also',\n",
       " 'captains',\n",
       " 'club',\n",
       " 'collections',\n",
       " 'fabulous',\n",
       " 'footballer',\n",
       " 'forward',\n",
       " 'going',\n",
       " 'known',\n",
       " 'mmwinemaker',\n",
       " 'national',\n",
       " 'online',\n",
       " 'plays',\n",
       " 'professional',\n",
       " 'raising',\n",
       " 'still',\n",
       " 'strong',\n",
       " 'team',\n",
       " 'wine',\n",
       " '·'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_words(tokenized_sents, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67a101d6-fda4-4140-9e23-7fda75728ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "frequency_feature_extraction = CountVectorizer(stop_words=\"english\")\n",
    "vectorized_sen_wc = frequency_feature_extraction.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10af6eca-8d3d-408d-b758-c9f977e61108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_sen_wc.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b63512eb-890c-4949-90db-0d43f6a6a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['andrés', 'argentina', 'argentine', 'captains', 'club',\n",
       "       'collections', 'fabulous', 'footballer', 'forward', 'going',\n",
       "       'head', 'inter', 'known', 'league', 'leo', 'lionel', 'major',\n",
       "       'messi', 'miami', 'mmwinemaker', 'national', 'online', 'plays',\n",
       "       'professional', 'raising', 'soccer', 'store', 'strong', 'team',\n",
       "       'thank', 'wine'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_feature_extraction.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f354d82-5fc1-4cff-81c2-6cc455e06441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_feature_extraction = TfidfVectorizer(stop_words=\"english\")\n",
    "vectorized_sen = tfidf_feature_extraction.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78f92b23-799c-4d5a-b4e8-a3b0c81328fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22069507, 0.22069507, 0.22069507, 0.22069507, 0.22069507,\n",
       "        0.        , 0.        , 0.22069507, 0.22069507, 0.        ,\n",
       "        0.        , 0.22069507, 0.22069507, 0.22069507, 0.22069507,\n",
       "        0.15702636, 0.22069507, 0.31405271, 0.22069507, 0.        ,\n",
       "        0.22069507, 0.        , 0.22069507, 0.22069507, 0.        ,\n",
       "        0.22069507, 0.        , 0.        , 0.22069507, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28852505, 0.28852505, 0.        , 0.        , 0.28852505,\n",
       "        0.28852505, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20528795, 0.        , 0.20528795, 0.        , 0.28852505,\n",
       "        0.        , 0.28852505, 0.        , 0.        , 0.28852505,\n",
       "        0.        , 0.28852505, 0.28852505, 0.        , 0.28852505,\n",
       "        0.28852505]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_sen.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166f21f-cd6b-4e76-8601-340788b8acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"persian.txt\", \"r\") as f:\n",
    "    persian_stop_words = [term.strip() for term in f.readlines()]\n",
    "# persian_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b610f9d-f832-48d4-bb03-8bfe35481bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=persian_stop_words)\n",
    "X_transformed = tfidf.fit_transform(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "91a0413a-175e-4f01-8be1-313919f39b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11016604, -0.01052942, -0.0069396 , ...,  0.00835152,\n",
       "         0.02741468,  0.01562451],\n",
       "       [ 0.25040681, -0.11688538, -0.00047366, ...,  0.0083801 ,\n",
       "        -0.00279721, -0.00077414],\n",
       "       [ 0.14778907, -0.03884731, -0.0435047 , ...,  0.00184133,\n",
       "         0.00299435,  0.00281458],\n",
       "       ...,\n",
       "       [ 0.19961209,  0.16177061, -0.08741312, ..., -0.01726428,\n",
       "        -0.00852969, -0.00278471],\n",
       "       [ 0.15808941, -0.07332478, -0.00163341, ..., -0.00669035,\n",
       "        -0.00921646,  0.01797244],\n",
       "       [ 0.10761828, -0.06943144, -0.01526881, ..., -0.00479121,\n",
       "        -0.01484706,  0.02545621]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "    \n",
    "pca = TruncatedSVD(n_components=1000)  ## data is sparse\n",
    "pca.fit_transform(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d16a9736-f80a-4b9f-bf1d-6fe47b7a4e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.774458239510194"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
